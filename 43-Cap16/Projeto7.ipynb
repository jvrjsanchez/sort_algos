{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvY-_7t6XMkK"
   },
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>IA Generativa e LLMs Para Processamento de Linguagem Natural</font>\n",
    "## <font color='blue'>Projeto 7</font>\n",
    "## <font color='blue'>Construindo Base de Conhecimento Para o LLM com Vector Database</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Se tiver dificuldade para executar o projeto localmente, execute no Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark.\n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=True\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=3\n"
     ]
    }
   ],
   "source": [
    "%env TF_CPP_MIN_LOG_LEVEL=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Para reproduzir o projeto use as versões dos pacotes conforme indicado ao final do capítulo. O projeto não foi testado em outras versões. Você é livre para usar a versão que desejar, mas nesse caso também é responsável por pesquisar a documentação e ajustar o código conforme necessário. Nosso objetivo aqui não é estudar versão de pacote e sim o processo de construção da solução baseada em LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TZ7f064HfTTW"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pypdf\n",
    "import chromadb\n",
    "import urllib3\n",
    "import accelerate\n",
    "import sentence_transformers\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH0dyHIpXSGp"
   },
   "source": [
    "## Extraindo Dados de Texto de Arquivos PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um objeto para carregar o arquivo PDF\n",
    "dsa_loader = PyPDFLoader(\"arquivos/ArtigoDSA1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.document_loaders.pdf.PyPDFLoader"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsa_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo PDF\n",
    "pages = dsa_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-18T06:02:27+00:00', 'author': 'DM PM', 'moddate': '2023-12-18T06:02:27+00:00', 'source': 'arquivos/ArtigoDSA1.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}, page_content='A Habilidade Mais Importante na Era da Inteligência Artificial \\n \\nA pandemia do COVID-19 acelerou o ritmo do desenvolvimento digital em todo o mundo, já que \\ntudo, desde reuniões até consultas médicas, ficou online. Isso pode soar como algo super \\npositivo.  \\nPara dezenas de milhões de trabalhadores, não. \\nEles talvez não tenham as habilidades necessárias para competir nesse novo mundo. Eles são os \\ncontadores, os digitadores, os secretários executivos, procurando trabalho em uma nova \\neconomia na qual as pessoas contratadas têm títulos como “Engenheiro de Nuv em” ou “Hacker \\nde Crescimento” em seus currículos. Sem um esforço concentrado para retreiná-los, descobriram \\nos pesquisadores da RAND Europe, eles provavelmente serão deixados para trás. \\nE não apenas eles. O custo dessa crescente lacuna de habilidades será medido em trilhões de \\ndólares e recairá mais fortemente em lugares que não possuem infraestrutura digital confiável, \\ncomo acesso à Internet ou fluência generalizada em habilidades digita is. À medida que a \\neconomia mundial luta para se levantar após o golpe do COVID -19, essa lacuna de habilidades \\nameaça continuar pressionando para baixo. \\n“Simplesmente não há pessoas suficientes com as habilidades digitais certas para permitir a \\ntransformação que as empresas estão buscando”, disse Salil Gunashekar, líder de pesquisa e \\ndiretor associado da RAND Europe, que se concentra na política de ciência e tecnologia. \\nEm algum momento nos próximos anos, o mundo passará por um marco importante. O número \\nde horas trabalhadas pelas máquinas será igual ao número de horas trabalhadas pelos humanos. \\nUma pesquisa recente da Salesforce descobriu que três quartos dos trabalhadores do mundo se \\nsentem despreparados para os empregos que podem encontrar do outro lado desse marco. \\nAqueles que planejam trabalhar em assistência médica ou serviços financeiros, por exemplo, \\npodem precisar saber como usar computadores com Inteligência Artificial. Aqueles que desejam \\ntrabalhar em mineração de metais podem precisar saber como operar robôs e analisar Big Data. \\nUm contador pode ser tornar o operador de um robô de automação de processos. \\nOs líderes empresariais alertam há anos que o que veem nos currículos não corresponde ao que \\nprecisam em novos funcionários. O Índice de Economia e Sociedade Digital da Europa descobriu \\nrecentemente que quase 60% dos empregadores estão tendo problemas para  preencher vagas \\ndigitais com candidatos qualificados. E, no entanto, as realidades pandêmicas não os deixaram \\nescolha: quatro em cada cinco líderes empresariais globais dizem que estão acelerando a \\nautomação de processos e tarefas do dia a dia dentro da empresa.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-18T06:02:27+00:00', 'author': 'DM PM', 'moddate': '2023-12-18T06:02:27+00:00', 'source': 'arquivos/ArtigoDSA1.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2'}, page_content='As principais economias do mundo agora podem perder US$ 11,5 trilhões em crescimento \\npotencial até 2028 se não conseguirem preencher a lacuna de habilidades, estimou a empresa \\nglobal de consultoria e serviços profissionais Accenture. Índia, África do Sul e  México serão \\nespecialmente atingidos. O mesmo acontecerá com os grupos que menos podem arcar com a \\nperda econômica: idosos, minorias raciais e étnicas e pessoas que vivem em áreas rurais. \\nO Fórum Econômico Mundial estima que 85 milhões de empregos podem ser perdidos para a \\nautomação nos próximos três anos em mais de uma dúzia de setores. Ao mesmo tempo, espera \\nque surjam 97 milhões de novos empregos melhor adaptados ao futuro do trabalho. N o papel, \\nisso deve ser uma vitória. Sem um grande compromisso para reter e retreinar os trabalhadores \\nexistentes, descobriu a RAND Europe, será uma perda para os funcionários e uma perda para os \\nempregadores. \\nNão há soluções simples aqui. As empresas precisam se tornar mais ágeis na distribuição e \\nredistribuição de seus funcionários existentes para melhor atender às suas necessidades, em vez \\nde tentar recrutar para sair da lacuna de habilidades. Elas também pre cisam fazer mais para \\najudar esses funcionários a aprender as habilidades técnicas, como programação e análise de \\ndados, e as habilidades interpessoais, como trabalhar em equipe, de que precisam para ter \\nsucesso. Os governos nacionais podem ajudar investin do em programas vocacionais e outros \\napoios para trabalhadores desalocados. \\nUm passo importante seria desenvolver uma “linguagem de habilidades” comum, escreveram os \\npesquisadores. Isso garantiria que candidatos e empregadores tivessem a mesma intenção ao \\nusar um termo como “Engenheiro de Nuvem” ou “Engenheiro de IA”. Isso ajudari a os gerentes \\nde contratação a avaliar rapidamente os candidatos com base nas habilidades que eles trazem \\npara o trabalho e não apenas no nome da faculdade em seu currículo (que no mundo atual já não \\ntem mais qualquer relevância). \\nOs trabalhadores, entretanto, precisam mudar sua mentalidade. A educação não termina mais \\ncom um diploma do ensino médio ou um diploma universitário. As habilidades que eles têm \\nagora podem não ser relevantes em alguns anos. Como aconselhou um gerente de tecnologia no \\nCanadá entrevistado durante a pesquisa: “Seja Bom em Aprender”. \\nSim. Esta é a habilidade mais importante na era da Inteligência Artificial:  \\n“Seja Bom em Aprender”. \\n \\nA transformação digital requer que você aprenda, desaprenda, reaprenda e permaneça nesse \\nciclo se deseja realmente manter sua empregabilidade. A capacidade de adaptação a novas \\ntecnologias e a habilidade em aprender cada vez mais rápido, é o que vai diferenciar você das \\nmáquinas.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-18T06:02:27+00:00', 'author': 'DM PM', 'moddate': '2023-12-18T06:02:27+00:00', 'source': 'arquivos/ArtigoDSA1.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3'}, page_content='Não importa sua área, seu mercado, sua graduação, sua idade ou seu gênero. O mundo está \\npassando por uma profunda transformação digital e os empregos como conhecemos estão sendo \\nreinventados. Aqueles que não acompanharem essa evolução natural ficarão para trás, como \\ntantas vezes vimos na história humana. Aprenda o máximo que puder, sobre diferentes temas, \\ndesde habilidades interpessoais até habilidades técnicas. O único limite sobre o que você pode \\naprender é o que você impõe a si mesmo. \\n“Seja Bom em Aprender”. Mantenha-se em modo constante de aprendizado. \\nEquipe DSA \\nwww.datascienceacademy.com.br')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos visualizar o conteúdeo de apenas uma página, neste caso da página 3 (indexação em Python começa por 0)\n",
    "page = pages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo da Página: Não importa sua área, seu mercado, sua graduação, sua idade ou seu gênero. O mundo está \n",
      "passando por uma profunda transformação digital e os empregos como conhecemos estão sendo \n",
      "reinventados. Aqueles que não acompanharem essa evolução natural ficarão para trás, como \n",
      "tantas vezes vimos na história humana. Aprenda o máximo que puder, sobre diferentes temas, \n",
      "desde habilidades interpessoais até habilidades técnicas. O único limite sobre o que você pode \n",
      "aprender é o que você impõe a si mesmo. \n",
      "“Seja Bom em Aprender”. Mantenha-se em modo constante de aprendizado. \n",
      "Equipe DSA \n",
      "www.datascienceacademy.com.br\n"
     ]
    }
   ],
   "source": [
    "print(\"Conteúdo da Página:\", page.page_content[0:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados da Página: {'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-18T06:02:27+00:00', 'author': 'DM PM', 'moddate': '2023-12-18T06:02:27+00:00', 'source': 'arquivos/ArtigoDSA1.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Metadados da Página:\", page.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão dos Dados de Texto em Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bZsTMV7fge6d"
   },
   "outputs": [],
   "source": [
    "# Cria o separador de chunks de texto\n",
    "dsa_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chunk_size = 1000**: Define que cada pedaço de texto resultante terá no máximo 1000 caracteres.\n",
    "\n",
    "**chunk_overlap = 20**: Indica que cada chunk terá 20 caracteres de sobreposição com o chunk seguinte. Isso significa que os últimos 20 caracteres de um chunk serão repetidos no início do próximo chunk.\n",
    "\n",
    "Para que serve:\n",
    "\n",
    "Essa abordagem é útil em várias situações onde textos grandes precisam ser processados ou analisados, como:\n",
    "\n",
    "- Entrada para modelos de linguagem: Muitos LLMs têm um limite de tokens que podem processar em uma única interação. Dividir o texto em pedaços menores garante que o texto seja enviado dentro do limite permitido.\n",
    "\n",
    "- Análise e indexação de dados: É comum em mecanismos de busca e pipelines de processamento de dados, onde dividir o texto em pedaços menores facilita a indexação e recuperação de informações.\n",
    "\n",
    "- Manutenção de contexto: Quando o processamento envolve documentos longos, essa técnica permite lidar com eles de forma mais eficiente, ao dividir as partes sem perder lógica ou coesão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o objeto e extrai os chunks (documentos)\n",
    "docs = dsa_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUApoxdSjqbl",
    "outputId": "a865970d-57d2-4501-cdbd-2a0d2a6c3320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Chunks (Documentos): 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de Chunks (Documentos):\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo do Último Chunk (Documento): page_content='Não importa sua área, seu mercado, sua graduação, sua idade ou seu gênero. O mundo está \n",
      "passando por uma profunda transformação digital e os empregos como conhecemos estão sendo \n",
      "reinventados. Aqueles que não acompanharem essa evolução natural ficarão para trás, como \n",
      "tantas vezes vimos na história humana. Aprenda o máximo que puder, sobre diferentes temas, \n",
      "desde habilidades interpessoais até habilidades técnicas. O único limite sobre o que você pode \n",
      "aprender é o que você impõe a si mesmo. \n",
      "“Seja Bom em Aprender”. Mantenha-se em modo constante de aprendizado. \n",
      "Equipe DSA \n",
      "www.datascienceacademy.com.br' metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-18T06:02:27+00:00', 'author': 'DM PM', 'moddate': '2023-12-18T06:02:27+00:00', 'source': 'arquivos/ArtigoDSA1.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Conteúdo do Último Chunk (Documento):\", docs[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fVm26IqXa0l"
   },
   "source": [
    "## Carregando os Vetores dos Dados de Texto no Banco de Dados Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código implementa um sistema de busca semântica utilizando um banco de dados vetorial (vectordb) para identificar os pontos mais relevantes em relação a uma pergunta, baseado na similaridade semântica entre os documentos e a questão fornecida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "https://www.trychroma.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zh6sz9eYjtjU",
    "outputId": "85b52438-b7e1-4032-ce1d-c64485945e41"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffae50a80e8478e8033f610a857f180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d981d14a4314f1f9088fbc1e7b668ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55fa9871f7d446fa40463b1bf647cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1b7419ca9f471e97220248af163c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136b53da40794776abc1705f0111c051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f98f48df4f94767ad959bff955ef316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fed2a49f124a9a8e3c21bc1bb8b500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c7ea215a3e40fd942b23480ebbb03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cab98bfc014a3aaf20ff1a112f2cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c5b86b84894ba495f71968fc05f44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40783d88972d4c24ae7d0abc1105727b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cria o banco de dados vetorial\n",
    "vectordb = Chroma.from_documents(documents = docs,\n",
    "                                 embedding = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\"),\n",
    "                                 persist_directory = \"dsavectordb/chroma/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chroma.from_documents(documents=docs)**: Cria um banco de dados vetorial utilizando os documentos fornecidos (armazenados na variável docs). Esses documentos podem ser textos, artigos ou qualquer tipo de dado textual que você deseja indexar.\n",
    "\n",
    "**HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")**: Usa o modelo de embeddings semânticos chamado all-MiniLM-L6-v2, da Hugging Face, para transformar os textos em vetores numéricos. Embeddings são representações matemáticas dos textos que capturam seu significado semântico.\n",
    "\n",
    "**persist_directory=\"dsavectordb/chroma/\"**: Especifica o diretório onde o banco de dados vetorial será salvo (persistido), para que possa ser reutilizado em sessões futuras sem a necessidade de reprocessar os documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de coleções no vector db\n",
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando os Parâmetros da Busca Vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uma questão\n",
    "questao = \"A pandemia do COVID-19 acelerou o ritmo do desenvolvimento digital em todo o mundo?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a busca vetorial\n",
    "pontos_relevantes = vectordb.max_marginal_relevance_search(questao, k = 2, fetch_k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_marginal_relevance_search()**: Realiza uma busca no banco de dados vetorial com base na relevância marginal máxima (MMR - Maximal Marginal Relevance). Essa técnica é usada para encontrar documentos relevantes para a questão fornecida, diminuindo a redundância nas respostas. Em vez de retornar documentos muito semelhantes entre si, ela garante diversidade nas respostas enquanto mantém a relevância. Leia o manual em pdf no Capítulo 16 com mais detalhes.\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "**questao**: A questão em texto natural usada para calcular a similaridade semântica com os documentos do banco de dados vetorial.\n",
    "\n",
    "**k=2**: Define o número de documentos finais que serão retornados como os mais relevantes.\n",
    "\n",
    "**fetch_k=3**: Especifica que o algoritmo deve buscar inicialmente os 3 documentos mais relevantes e, em seguida, aplicar a técnica de MMR para selecionar os 2 mais diversificados e relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0Ttw12-nZE1",
    "outputId": "e9694eaa-94c0-4142-bcea-0c0795bed973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='A Habilidade Mais Importante na Era da Inteligência Artificial \n",
      " \n",
      "A pandemia do COVID-19 acelerou o ritmo do desenvolvimento digital em todo o mundo, já que \n",
      "tudo, desde reuniões até consultas médicas, ficou online. Isso pode soar como algo super \n",
      "positivo.  \n",
      "Para dezenas de milhões de trabalhadores, não. \n",
      "Eles talvez não tenham as habilidades necessárias para competir nesse novo mundo. Eles são os \n",
      "contadores, os digitadores, os secretários executivos, procurando trabalho em uma nova \n",
      "economia na qual as pessoas contratadas têm títulos como “Engenheiro de Nuv em” ou “Hacker \n",
      "de Crescimento” em seus currículos. Sem um esforço concentrado para retreiná-los, descobriram \n",
      "os pesquisadores da RAND Europe, eles provavelmente serão deixados para trás. \n",
      "E não apenas eles. O custo dessa crescente lacuna de habilidades será medido em trilhões de \n",
      "dólares e recairá mais fortemente em lugares que não possuem infraestrutura digital confiável,' metadata={'total_pages': 3, 'creator': 'Microsoft Word', 'creationdate': '2023-12-18T06:02:27+00:00', 'page_label': '1', 'source': 'arquivos/ArtigoDSA1.pdf', 'author': 'DM PM', 'producer': 'PyPDF', 'page': 0, 'moddate': '2023-12-18T06:02:27+00:00'}\n"
     ]
    }
   ],
   "source": [
    "print(pontos_relevantes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgP4CEPJXghn"
   },
   "source": [
    "## Definindo o LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nome do LLM conforme consta no HF\n",
    "nome_modelo_llm = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abae18f94eb2458f84048313c15095ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8784b0a4e5904bf59d2f2a7b6950ba18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4eb8af31a82451282a4f02fa40530a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega o modelo\n",
    "modelo = AutoModelForCausalLM.from_pretrained(nome_modelo_llm,\n",
    "                                              torch_dtype = \"auto\",\n",
    "                                              device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5d91231e1846a6b97eaa4ec1930b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35177f582ef34865a828a555e69729c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dc0b74b688483e9d829f59a7908570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecba7d1914e3424a84399399e4f1dfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega o tokenizador do modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(nome_modelo_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando o Contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fmWtR2smp1B7"
   },
   "outputs": [],
   "source": [
    "# Define a questão\n",
    "questao = \"A pandemia do COVID-19 acelerou o ritmo do desenvolvimento digital em todo o mundo?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai o contexto da questão (ou seja, executa a busca vetorial)\n",
    "contexto = vectordb.max_marginal_relevance_search(questao, k = 2, fetch_k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando o Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o prompt\n",
    "prompt = f\"\"\"\n",
    "Você é um assistente especialista. Você usa o contexto fornecido como sua base de conhecimento complementar para responder à pergunta.\n",
    "context = {contexto}\n",
    "question = {questao}\n",
    "answer =\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a lista de mensagens de systema e de usuário\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você é Qwen, criado pela Alibaba Cloud. Você é um assistente especialista.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização do Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o chat template\n",
    "texto = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nVocê é Qwen, criado pela Alibaba Cloud. Você é um assistente especialista.<|im_end|>\\n<|im_start|>user\\n\\nVocê é um assistente especialista. Você usa o contexto fornecido como sua base de conhecimento complementar para responder à pergunta.\\ncontext = [Document(metadata={'creationdate': '2023-12-18T06:02:27+00:00', 'author': 'DM PM', 'moddate': '2023-12-18T06:02:27+00:00', 'creator': 'Microsoft Word', 'producer': 'PyPDF', 'source': 'arquivos/ArtigoDSA1.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}, page_content='A Habilidade Mais Importante na Era da Inteligência Artificial \\\\n \\\\nA pandemia do COVID-19 acelerou o ritmo do desenvolvimento digital em todo o mundo, já que \\\\ntudo, desde reuniões até consultas médicas, ficou online. Isso pode soar como algo super \\\\npositivo.  \\\\nPara dezenas de milhões de trabalhadores, não. \\\\nEles talvez não tenham as habilidades necessárias para competir nesse novo mundo. Eles são os \\\\ncontadores, os digitadores, os secretários executivos, procurando trabalho em uma nova \\\\neconomia na qual as pessoas contratadas têm títulos como “Engenheiro de Nuv em” ou “Hacker \\\\nde Crescimento” em seus currículos. Sem um esforço concentrado para retreiná-los, descobriram \\\\nos pesquisadores da RAND Europe, eles provavelmente serão deixados para trás. \\\\nE não apenas eles. O custo dessa crescente lacuna de habilidades será medido em trilhões de \\\\ndólares e recairá mais fortemente em lugares que não possuem infraestrutura digital confiável,'), Document(metadata={'author': 'DM PM', 'total_pages': 3, 'creator': 'Microsoft Word', 'source': 'arquivos/ArtigoDSA1.pdf', 'moddate': '2023-12-18T06:02:27+00:00', 'producer': 'PyPDF', 'page': 0, 'page_label': '1', 'creationdate': '2023-12-18T06:02:27+00:00'}, page_content='como acesso à Internet ou fluência generalizada em habilidades digita is. À medida que a \\\\neconomia mundial luta para se levantar após o golpe do COVID -19, essa lacuna de habilidades \\\\nameaça continuar pressionando para baixo. \\\\n“Simplesmente não há pessoas suficientes com as habilidades digitais certas para permitir a \\\\ntransformação que as empresas estão buscando”, disse Salil Gunashekar, líder de pesquisa e \\\\ndiretor associado da RAND Europe, que se concentra na política de ciência e tecnologia. \\\\nEm algum momento nos próximos anos, o mundo passará por um marco importante. O número \\\\nde horas trabalhadas pelas máquinas será igual ao número de horas trabalhadas pelos humanos. \\\\nUma pesquisa recente da Salesforce descobriu que três quartos dos trabalhadores do mundo se \\\\nsentem despreparados para os empregos que podem encontrar do outro lado desse marco. \\\\nAqueles que planejam trabalhar em assistência médica ou serviços financeiros, por exemplo,')]\\nquestion = A pandemia do COVID-19 acelerou o ritmo do desenvolvimento digital em todo o mundo?\\nanswer =\\n<|im_end|>\\n<|im_start|>assistant\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a tokenização\n",
    "model_inputs = tokenizer([texto], return_tensors = \"pt\").to(modelo.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,  69286,   3958,   1207,  16948,     11,  27558,\n",
       "           2123,  32723,  54364,  14817,     13,  80797,   3958,   4443,   7789,\n",
       "           6817,  32297,   9087,     13, 151645,    198, 151644,    872,    271,\n",
       "          69286,   3958,   4443,   7789,   6817,  32297,   9087,     13,  80797,\n",
       "          33715,    297,  76743,  56009,    757,   5249,   7953,  19345,   2331,\n",
       "            409,  70483,  15027,  22766,    277,   3348,  64034,   3784,    817,\n",
       "          59910,    624,   2147,    284,    508,   7524,  54436,  12854,  37375,\n",
       "           1028,   1210,    364,     17,     15,     17,     18,     12,     16,\n",
       "             17,     12,     16,     23,     51,     15,     21,     25,     15,\n",
       "             17,     25,     17,     22,     10,     15,     15,     25,     15,\n",
       "             15,    516,    364,   3094,   1210,    364,   8395,   5851,    516,\n",
       "            364,   2593,   1028,   1210,    364,     17,     15,     17,     18,\n",
       "             12,     16,     17,     12,     16,     23,     51,     15,     21,\n",
       "             25,     15,     17,     25,     17,     22,     10,     15,     15,\n",
       "             25,     15,     15,    516,    364,  32398,   1210,    364,  12778,\n",
       "           9322,    516,    364,  58912,   1210,    364,  13828,  23424,    516,\n",
       "            364,   2427,   1210,    364,    277,  86231,     14,   9286,   7836,\n",
       "          72638,     16,  15995,    516,    364,   5035,  21655,   1210,    220,\n",
       "             18,     11,    364,   2893,   1210,    220,     15,     11,    364,\n",
       "           2893,   6106,   1210,    364,     16,  24731,   2150,   7495,   1131,\n",
       "             32,    472,  79916,  33347,  13213,   4942,   4317,  47588,   2994,\n",
       "          15611,    343,  23696,  58194,   1124,     77,   1124,     77,     32,\n",
       "          12217,  21925,    653,  19966,     12,     16,     24,   1613,   7865,\n",
       "            283,    297,  21198,   6355,    653,  60244,  78669,   7377,    976,\n",
       "          11804,    297,  28352,     11,  32092,   1709,   1124,    406,   7680,\n",
       "             11,  22718,    312,  15705,  12652,  38483,   8498,    300,  33930,\n",
       "          15185,     11,  41255,    283,   2860,     13,   2160,    704,  28194,\n",
       "          98465,   7953,  27928,   2256,   1124,     77,   2724,   6496,     13,\n",
       "            220,   1124,     77,  30205,    409,   5679,    300,    409, 133893,\n",
       "            409,  36268,     71,  18244,     11,  12393,     13,   1124,     77,\n",
       "             36,    642,   8210,  19069,  12393,   5779,   5604,    438,  94215,\n",
       "          13596,   4441,   1953,  47831,   3348,   4533,    404,    308,  23318,\n",
       "          38323,  28352,     13,    468,    642,  29610,   2643,   1124,     77,\n",
       "            772,  18244,     11,   2643,  15723,  18244,     11,   2643,   6234,\n",
       "          37085,  23494,  24224,     11,  70502,   4883,  54639,    976,  10608,\n",
       "          40534,   1124,    811,  44217,    685,   4317,   5841,    438,  45962,\n",
       "          87003,  11107,  98860,    259,  16095,  28652,   7953,   1036,   4106,\n",
       "            268,  59477,    409,    451,  12058,    976,    854,   5908,   1036,\n",
       "             39,   9683,   1124,  42341,  60910,     66,  15027,    854,    976,\n",
       "          41398,   9804,  66011,     13,  14248,   4443,   1531,   1958,  20210,\n",
       "          17137,   2123,   3348,   2112,    265,    258,   1953,     12,   2301,\n",
       "             11,   6560,    674,  37215,    309,   1124,  36391,  18050,   9202,\n",
       "          18244,   2994,  72854,   4505,     11,  66441,   2543,   3878,  12541,\n",
       "          98424,  64756,   5553,   3348,    489,   7061,     13,   1124,     77,\n",
       "             36,  12393,  46667,  66441,     13,    506,  16564,     78,  85479,\n",
       "          45758,  77584,  43879,   8565,    409,  94215,  13596,  32898,   1774,\n",
       "           5249,    976,    489,    321,  93230,    409,   1124,    303,   1794,\n",
       "           4260,    416,    384,    312,    924,  83562,   9870,    369,    870,\n",
       "           6817,    976,  92824,   1709,  12393,   2229,  69847,  48176,  15111,\n",
       "          78707,   7377,   2335,     72,  43315,   2894,    701,  11789,  54436,\n",
       "          12854,   3094,   1210,    364,   8395,   5851,    516,    364,   5035,\n",
       "          21655,   1210,    220,     18,     11,    364,  32398,   1210,    364,\n",
       "          12778,   9322,    516,    364,   2427,   1210,    364,    277,  86231,\n",
       "             14,   9286,   7836,  72638,     16,  15995,    516,    364,   2593,\n",
       "           1028,   1210,    364,     17,     15,     17,     18,     12,     16,\n",
       "             17,     12,     16,     23,     51,     15,     21,     25,     15,\n",
       "             17,     25,     17,     22,     10,     15,     15,     25,     15,\n",
       "             15,    516,    364,  58912,   1210,    364,  13828,  23424,    516,\n",
       "            364,   2893,   1210,    220,     15,     11,    364,   2893,   6106,\n",
       "           1210,    364,     16,    516,    364,  37375,   1028,   1210,    364,\n",
       "             17,     15,     17,     18,     12,     16,     17,     12,     16,\n",
       "             23,     51,     15,     21,     25,     15,     17,     25,     17,\n",
       "             22,     10,     15,     15,     25,     15,     15,  24731,   2150,\n",
       "           7495,   1131,  96296,  83707,   3784,   8031,   5908,  19660,  23696,\n",
       "           4586,  51211,    976,  94215,  13596,   4078,   6255,    374,     13,\n",
       "          64281,  71528,   1709,    264,   1124,    811,  44217,    685,  97087,\n",
       "            326,  15999,   3348,    511,  22638,  88965,  75081,    297,  44449,\n",
       "            375,    653,  19966,    481,     16,     24,     11,  54629,  43879,\n",
       "           8565,    409,  94215,  13596,   1124,    606,     64,  17472,  71007,\n",
       "           3493,    290,   4883,   3348,  12789,  51362,     13,   1124,     77,\n",
       "           2073,     50,   6664,    642,  12541,  12393,  42122,  45962,  55768,\n",
       "           5385,    288,    469,    438,  94215,  13596,  15723,   2782,   2777,\n",
       "            300,   3348,  11549,    404,    264,   1124,     77,   4701,  12967,\n",
       "           1709,    438,  50304,  56454,  63182,   4883,   9336,  32900,   8211,\n",
       "            321,  21707,    300,    383,  28134,     11,  94696,    409,  94630,\n",
       "            384,   1124,    303,    554,  10980,   4097,   2123,   2994,  72854,\n",
       "           4505,     11,   1709,    511,  10014,    956,   4317,  61489,    409,\n",
       "          11825,  23696,    384,  40834,  37973,     13,   1124,     77,   2269,\n",
       "          96675,  30121,  11891,  29291,     87,  24107,  37001,     11,    297,\n",
       "          28352,   1494,  30741,   4154,   4443,   3594,   1015,  35797,     13,\n",
       "            506,  30211,   1124,  42341,  38892,  36268,     71,  11107,  11814,\n",
       "            300,  28730,    446,  20114,  32898,  43475,  14845,  30211,    409,\n",
       "          38892,  36268,     71,  11107,  82839,   3738,    436,     13,   1124,\n",
       "             77,     52,   1728,  94630,   3213,     68,   2994,  80935,   6560,\n",
       "            674,    461,     84,   1709,  81529,  40276,    436,   8750,  36268,\n",
       "             71,  18244,    653,  28352,    511,   1124,   4412,    306,    336,\n",
       "          86625,   1732,   5553,   3348,   2643,   8486,   1580,    436,   1709,\n",
       "          62676,  45623,    653,  60658,  43424,    939,    325,   3594,   1015,\n",
       "             13,   1124,     77,     32,    591,    642,   1709,  11031,  43711,\n",
       "          36268,  12982,    976,   7789,  23696, 133272,   5908,  93743,  17017,\n",
       "          47228,     11,   4154,  79594,     11,  49624,   7841,    284,    362,\n",
       "          12217,  21925,    653,  19966,     12,     16,     24,   1613,   7865,\n",
       "            283,    297,  21198,   6355,    653,  60244,  78669,   7377,    976,\n",
       "          11804,    297,  28352,   5267,   9217,   4035, 151645,    198, 151644,\n",
       "          77091,    198]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando Resposta com o LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera resposta com o LLM\n",
    "generated_ids = modelo.generate(**model_inputs, max_new_tokens = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,  69286,   3958,   1207,  16948,     11,  27558,\n",
       "           2123,  32723,  54364,  14817,     13,  80797,   3958,   4443,   7789,\n",
       "           6817,  32297,   9087,     13, 151645,    198, 151644,    872,    271,\n",
       "          69286,   3958,   4443,   7789,   6817,  32297,   9087,     13,  80797,\n",
       "          33715,    297,  76743,  56009,    757,   5249,   7953,  19345,   2331,\n",
       "            409,  70483,  15027,  22766,    277,   3348,  64034,   3784,    817,\n",
       "          59910,    624,   2147,    284,    508,   7524,  54436,  12854,  37375,\n",
       "           1028,   1210,    364,     17,     15,     17,     18,     12,     16,\n",
       "             17,     12,     16,     23,     51,     15,     21,     25,     15,\n",
       "             17,     25,     17,     22,     10,     15,     15,     25,     15,\n",
       "             15,    516,    364,   3094,   1210,    364,   8395,   5851,    516,\n",
       "            364,   2593,   1028,   1210,    364,     17,     15,     17,     18,\n",
       "             12,     16,     17,     12,     16,     23,     51,     15,     21,\n",
       "             25,     15,     17,     25,     17,     22,     10,     15,     15,\n",
       "             25,     15,     15,    516,    364,  32398,   1210,    364,  12778,\n",
       "           9322,    516,    364,  58912,   1210,    364,  13828,  23424,    516,\n",
       "            364,   2427,   1210,    364,    277,  86231,     14,   9286,   7836,\n",
       "          72638,     16,  15995,    516,    364,   5035,  21655,   1210,    220,\n",
       "             18,     11,    364,   2893,   1210,    220,     15,     11,    364,\n",
       "           2893,   6106,   1210,    364,     16,  24731,   2150,   7495,   1131,\n",
       "             32,    472,  79916,  33347,  13213,   4942,   4317,  47588,   2994,\n",
       "          15611,    343,  23696,  58194,   1124,     77,   1124,     77,     32,\n",
       "          12217,  21925,    653,  19966,     12,     16,     24,   1613,   7865,\n",
       "            283,    297,  21198,   6355,    653,  60244,  78669,   7377,    976,\n",
       "          11804,    297,  28352,     11,  32092,   1709,   1124,    406,   7680,\n",
       "             11,  22718,    312,  15705,  12652,  38483,   8498,    300,  33930,\n",
       "          15185,     11,  41255,    283,   2860,     13,   2160,    704,  28194,\n",
       "          98465,   7953,  27928,   2256,   1124,     77,   2724,   6496,     13,\n",
       "            220,   1124,     77,  30205,    409,   5679,    300,    409, 133893,\n",
       "            409,  36268,     71,  18244,     11,  12393,     13,   1124,     77,\n",
       "             36,    642,   8210,  19069,  12393,   5779,   5604,    438,  94215,\n",
       "          13596,   4441,   1953,  47831,   3348,   4533,    404,    308,  23318,\n",
       "          38323,  28352,     13,    468,    642,  29610,   2643,   1124,     77,\n",
       "            772,  18244,     11,   2643,  15723,  18244,     11,   2643,   6234,\n",
       "          37085,  23494,  24224,     11,  70502,   4883,  54639,    976,  10608,\n",
       "          40534,   1124,    811,  44217,    685,   4317,   5841,    438,  45962,\n",
       "          87003,  11107,  98860,    259,  16095,  28652,   7953,   1036,   4106,\n",
       "            268,  59477,    409,    451,  12058,    976,    854,   5908,   1036,\n",
       "             39,   9683,   1124,  42341,  60910,     66,  15027,    854,    976,\n",
       "          41398,   9804,  66011,     13,  14248,   4443,   1531,   1958,  20210,\n",
       "          17137,   2123,   3348,   2112,    265,    258,   1953,     12,   2301,\n",
       "             11,   6560,    674,  37215,    309,   1124,  36391,  18050,   9202,\n",
       "          18244,   2994,  72854,   4505,     11,  66441,   2543,   3878,  12541,\n",
       "          98424,  64756,   5553,   3348,    489,   7061,     13,   1124,     77,\n",
       "             36,  12393,  46667,  66441,     13,    506,  16564,     78,  85479,\n",
       "          45758,  77584,  43879,   8565,    409,  94215,  13596,  32898,   1774,\n",
       "           5249,    976,    489,    321,  93230,    409,   1124,    303,   1794,\n",
       "           4260,    416,    384,    312,    924,  83562,   9870,    369,    870,\n",
       "           6817,    976,  92824,   1709,  12393,   2229,  69847,  48176,  15111,\n",
       "          78707,   7377,   2335,     72,  43315,   2894,    701,  11789,  54436,\n",
       "          12854,   3094,   1210,    364,   8395,   5851,    516,    364,   5035,\n",
       "          21655,   1210,    220,     18,     11,    364,  32398,   1210,    364,\n",
       "          12778,   9322,    516,    364,   2427,   1210,    364,    277,  86231,\n",
       "             14,   9286,   7836,  72638,     16,  15995,    516,    364,   2593,\n",
       "           1028,   1210,    364,     17,     15,     17,     18,     12,     16,\n",
       "             17,     12,     16,     23,     51,     15,     21,     25,     15,\n",
       "             17,     25,     17,     22,     10,     15,     15,     25,     15,\n",
       "             15,    516,    364,  58912,   1210,    364,  13828,  23424,    516,\n",
       "            364,   2893,   1210,    220,     15,     11,    364,   2893,   6106,\n",
       "           1210,    364,     16,    516,    364,  37375,   1028,   1210,    364,\n",
       "             17,     15,     17,     18,     12,     16,     17,     12,     16,\n",
       "             23,     51,     15,     21,     25,     15,     17,     25,     17,\n",
       "             22,     10,     15,     15,     25,     15,     15,  24731,   2150,\n",
       "           7495,   1131,  96296,  83707,   3784,   8031,   5908,  19660,  23696,\n",
       "           4586,  51211,    976,  94215,  13596,   4078,   6255,    374,     13,\n",
       "          64281,  71528,   1709,    264,   1124,    811,  44217,    685,  97087,\n",
       "            326,  15999,   3348,    511,  22638,  88965,  75081,    297,  44449,\n",
       "            375,    653,  19966,    481,     16,     24,     11,  54629,  43879,\n",
       "           8565,    409,  94215,  13596,   1124,    606,     64,  17472,  71007,\n",
       "           3493,    290,   4883,   3348,  12789,  51362,     13,   1124,     77,\n",
       "           2073,     50,   6664,    642,  12541,  12393,  42122,  45962,  55768,\n",
       "           5385,    288,    469,    438,  94215,  13596,  15723,   2782,   2777,\n",
       "            300,   3348,  11549,    404,    264,   1124,     77,   4701,  12967,\n",
       "           1709,    438,  50304,  56454,  63182,   4883,   9336,  32900,   8211,\n",
       "            321,  21707,    300,    383,  28134,     11,  94696,    409,  94630,\n",
       "            384,   1124,    303,    554,  10980,   4097,   2123,   2994,  72854,\n",
       "           4505,     11,   1709,    511,  10014,    956,   4317,  61489,    409,\n",
       "          11825,  23696,    384,  40834,  37973,     13,   1124,     77,   2269,\n",
       "          96675,  30121,  11891,  29291,     87,  24107,  37001,     11,    297,\n",
       "          28352,   1494,  30741,   4154,   4443,   3594,   1015,  35797,     13,\n",
       "            506,  30211,   1124,  42341,  38892,  36268,     71,  11107,  11814,\n",
       "            300,  28730,    446,  20114,  32898,  43475,  14845,  30211,    409,\n",
       "          38892,  36268,     71,  11107,  82839,   3738,    436,     13,   1124,\n",
       "             77,     52,   1728,  94630,   3213,     68,   2994,  80935,   6560,\n",
       "            674,    461,     84,   1709,  81529,  40276,    436,   8750,  36268,\n",
       "             71,  18244,    653,  28352,    511,   1124,   4412,    306,    336,\n",
       "          86625,   1732,   5553,   3348,   2643,   8486,   1580,    436,   1709,\n",
       "          62676,  45623,    653,  60658,  43424,    939,    325,   3594,   1015,\n",
       "             13,   1124,     77,     32,    591,    642,   1709,  11031,  43711,\n",
       "          36268,  12982,    976,   7789,  23696, 133272,   5908,  93743,  17017,\n",
       "          47228,     11,   4154,  79594,     11,  49624,   7841,    284,    362,\n",
       "          12217,  21925,    653,  19966,     12,     16,     24,   1613,   7865,\n",
       "            283,    297,  21198,   6355,    653,  60244,  78669,   7377,    976,\n",
       "          11804,    297,  28352,   5267,   9217,   4035, 151645,    198, 151644,\n",
       "          77091,    198,  14027,     11,    264,  12217,  21925,    653,  19966,\n",
       "             12,     16,     24,   1613,   7865,    283,   4595,  19488,   8980,\n",
       "            297,  21198,   6355,    653,  60244,  78669,   7377,    976,  11804,\n",
       "            297,  28352,     13,  38676,  81636,    902,  33910,   6616,  40834,\n",
       "           1609,   3473,  15723,   2782,  21679,  24524,   2123,  27525,  13098,\n",
       "          10411,   3590,   1709,   1102,    283,   2994,   1560,   1064,  19812,\n",
       "          57942,     11,  22638,   4883,  53760,    436,    264,   9772,    277,\n",
       "          52097,  68332,  13596, 143565,  47831,   3348,  62786,    627,    300,\n",
       "            389,   8447,     13, 133036,    827,    704,     11,    264,   4441,\n",
       "           9075,  60839,   6817,    409,    993,    354,    277,   2048,     84,\n",
       "          15249,  15723,   2782,   3348,    883,    465,    438,   1997,  33465,\n",
       "          27863,   2782,  29231,    297,  86624,    409,    922,   1390,   7157,\n",
       "          34601,   5919,   1963,     84,   3348,  10351,  97320,   1822,    276,\n",
       "          20210,     13, 151645]], device='mps:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descompacta as respostas\n",
    "# Objetivo: Extrair apenas os tokens gerados pelo modelo (ou seja, a parte da saída que vem após \n",
    "# os tokens de entrada). Isso é útil, pois os modelos como GPT ou outros baseados em decodificação \n",
    "# autoregressiva frequentemente retornam uma concatenação da entrada e da saída.\n",
    "generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, \n",
    "                                                                              generated_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 14027,     11,    264,  12217,  21925,    653,  19966,     12,     16,\n",
       "             24,   1613,   7865,    283,   4595,  19488,   8980,    297,  21198,\n",
       "           6355,    653,  60244,  78669,   7377,    976,  11804,    297,  28352,\n",
       "             13,  38676,  81636,    902,  33910,   6616,  40834,   1609,   3473,\n",
       "          15723,   2782,  21679,  24524,   2123,  27525,  13098,  10411,   3590,\n",
       "           1709,   1102,    283,   2994,   1560,   1064,  19812,  57942,     11,\n",
       "          22638,   4883,  53760,    436,    264,   9772,    277,  52097,  68332,\n",
       "          13596, 143565,  47831,   3348,  62786,    627,    300,    389,   8447,\n",
       "             13, 133036,    827,    704,     11,    264,   4441,   9075,  60839,\n",
       "           6817,    409,    993,    354,    277,   2048,     84,  15249,  15723,\n",
       "           2782,   3348,    883,    465,    438,   1997,  33465,  27863,   2782,\n",
       "          29231,    297,  86624,    409,    922,   1390,   7157,  34601,   5919,\n",
       "           1963,     84,   3348,  10351,  97320,   1822,    276,  20210,     13,\n",
       "         151645], device='mps:0')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o decode para obter o texto gerado\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim, a pandemia do COVID-19 acelerou significativamente o ritmo do desenvolvimento digital em todo o mundo. Este aumento no uso das tecnologias digitais foi causado pelo isolamento social que resultou da crise sanitária, levando muitos a migrar suas atividades diárias para plataformas on-line. Além disso, a necessidade urgente de adotar soluções digitais para manter as operações funcionais durante o período de quarentena também contribuiu para este rápido avanço.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de Perguntas e Respostas Usando a Base de Conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De acordo com o documento, o Fórum Econômico Mundial estima que 85 milhões de empregos poderão ser perdidos para automação nos próximos três anos em mais de um duzentos e dezesseis setores.\n"
     ]
    }
   ],
   "source": [
    "# Define a questão\n",
    "questao = \"Quantos empregos o Fórum Econômico Mundial estima que serão perdidos para automação nos próximos anos?\"\n",
    "\n",
    "# Extrai o contexto da questão (ou seja, executa a busca vetorial)\n",
    "contexto = vectordb.max_marginal_relevance_search(questao, k = 2, fetch_k = 3)\n",
    "\n",
    "# Cria o prompt\n",
    "prompt = f\"\"\"\n",
    "Você é um assistente especialista. Você usa o contexto fornecido como sua base de conhecimento compplementar para responder à pergunta.\n",
    "context = {contexto}\n",
    "question = {questao}\n",
    "answer =\n",
    "\"\"\"\n",
    "\n",
    "# Cria a lista de mensagens de systema e de usuário\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você é Qwen, criado pela Alibaba Cloud. Você é um assistente especialista.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "# Aplica o chat template\n",
    "texto = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "# Aplica a tokenização\n",
    "model_inputs = tokenizer([texto], return_tensors = \"pt\").to(modelo.device)\n",
    "\n",
    "# Gera resposta com o LLM\n",
    "generated_ids = modelo.generate(**model_inputs, max_new_tokens = 512)\n",
    "\n",
    "# Descompacta as respostas\n",
    "generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, \n",
    "                                                                              generated_ids)]\n",
    "\n",
    "# Aplica o decode para obter o texto gerado\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens = True)[0]\n",
    "\n",
    "print(response)                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A habilidade mais importante na era da Inteligência Artificial é aprender constantemente, seja sobre habilidades interpessoais ou técnicas. A capacidade de se adaptar rapidamente às mudanças tecnológicas e manter-se atualizado é crucial para se manter competitivo no mercado de trabalho durante a era da IA.\n"
     ]
    }
   ],
   "source": [
    "# Define a questão\n",
    "questao = \"Qual é a habilidade mais importante na era da Inteligência Artificial?\"\n",
    "\n",
    "# Extrai o contexto da questão (ou seja, executa a busca vetorial)\n",
    "contexto = vectordb.max_marginal_relevance_search(questao, k = 2, fetch_k = 3)\n",
    "\n",
    "# Cria o prompt\n",
    "prompt = f\"\"\"\n",
    "Você é um assistente especialista. Você usa o contexto fornecido como sua base de conhecimento compplementar para responder à pergunta.\n",
    "context = {contexto}\n",
    "question = {questao}\n",
    "answer =\n",
    "\"\"\"\n",
    "\n",
    "# Cria a lista de mensagens de systema e de usuário\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você é Qwen, criado pela Alibaba Cloud. Você é um assistente especialista.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "# Aplica o chat template\n",
    "texto = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "# Aplica a tokenização\n",
    "model_inputs = tokenizer([texto], return_tensors = \"pt\").to(modelo.device)\n",
    "\n",
    "# Gera resposta com o LLM\n",
    "generated_ids = modelo.generate(**model_inputs, max_new_tokens = 512)\n",
    "\n",
    "# Descompacta as respostas\n",
    "generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, \n",
    "                                                                              generated_ids)]\n",
    "\n",
    "# Aplica o decode para obter o texto gerado\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens = True)[0]\n",
    "\n",
    "print(response)                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%watermark -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rvY-_7t6XMkK",
    "pH0dyHIpXSGp",
    "7fVm26IqXa0l",
    "rgP4CEPJXghn"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
